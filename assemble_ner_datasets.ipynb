{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONLL 2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_reader(inpt_file):\n",
    "    f = open(inpt_file, \"r\")\n",
    "    tok_lst = []\n",
    "    label_lst = []\n",
    "    for ix, x in enumerate(f):\n",
    "        if x == '\\n':\n",
    "            tok_lst.append('')\n",
    "            label_lst.append('')\n",
    "            continue\n",
    "        line = x.split()\n",
    "        tok = line[0]\n",
    "        try:\n",
    "            label = line[-1]\n",
    "        except:\n",
    "            print(line, ix)\n",
    "        tok_lst.append(tok)\n",
    "        label_lst.append(label)\n",
    "    f.close()\n",
    "    d = {'token':tok_lst,'ner':label_lst}\n",
    "    df = pd.DataFrame(d, columns=['token','ner'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "conl2003_train = txt_reader(\"conll2003/eng.train\")\n",
    "conl2003_testa = txt_reader(\"conll2003/eng.testa\")\n",
    "conl2003_testb = txt_reader(\"conll2003/eng.testb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "conl2003=pd.concat([conl2003_train,conl2003_testa,conl2003_testb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(324948, 2)"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conl2003.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIST-IEER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package ieer to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package ieer is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "nltk.download('ieer')\n",
    "from nltk.corpus import ieer\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_file_path = '/home/ubuntu/bert-ner-datasets/nltk_ieer_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ieer_reader(inpt_file):\n",
    "    f = open(inpt_file, \"r\")\n",
    "    last_line = ''\n",
    "    tok_lst = []\n",
    "    label_lst = []\n",
    "    for ix, x in enumerate(f):\n",
    "        x = x.strip()\n",
    "        if x == '(DOCUMENT':\n",
    "            tok_lst.append('-DOCSTART-')\n",
    "            label_lst.append('O')\n",
    "            tok_lst.append('')\n",
    "            label_lst.append('')\n",
    "            continue\n",
    "        if len(last_line) > 0:\n",
    "            if last_line[-1] == '.' and (x[0].isupper() or x[0].isalnum()):\n",
    "                tok_lst.append('')\n",
    "                label_lst.append('')\n",
    "        if x[0] == '(' and x[-1] == ')':\n",
    "            if x[-2] == ')':\n",
    "                continue\n",
    "            x = x[1:-1]\n",
    "            line = x.split()\n",
    "            label = line[0]\n",
    "            tok = line[-1]\n",
    "        else:\n",
    "            label = 'O'\n",
    "            tok = x\n",
    "        tok_lst.append(tok)\n",
    "        label_lst.append(label)\n",
    "        last_line = x #persist last line\n",
    "    f.close()\n",
    "    d = {'token':tok_lst,'ner':label_lst}\n",
    "    df = pd.DataFrame(d, columns=['token','ner'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_ieer = pd.DataFrame([])\n",
    "count=0\n",
    "for root, dirs, files in os.walk(nltk_file_path):\n",
    "    for fname in files:\n",
    "        if re.match(\".*.txt\",fname):\n",
    "            temp = ieer_reader(os.path.join(root,fname))\n",
    "            nltk_ieer = nltk_ieer.append(temp, ignore_index=True)\n",
    "            count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(nltk_file_path):\n",
    "    print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60063, 2)"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_ieer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMB-2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmb_file_path = '/home/ubuntu/bert-ner-datasets/GMB22/gmb-2.2.0/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmb_reader(inpt_file):\n",
    "    f = open(inpt_file, \"r\")\n",
    "    tok_lst = ['-DOCSTART-', '']\n",
    "    label_lst = ['O', '']\n",
    "    for ix, x in enumerate(f):\n",
    "        if x == '\\n':\n",
    "            tok_lst.append('')\n",
    "            label_lst.append('')\n",
    "            continue\n",
    "        try:\n",
    "            split_sent = x.split('\\t')\n",
    "            tok = split_sent[0]\n",
    "            label = split_sent[3]\n",
    "            tok_lst.append(tok)\n",
    "            label_lst.append(label)\n",
    "        except:\n",
    "            print(ix, x, tok_lst[-1], label_lst[-1])\n",
    "    f.close()\n",
    "    tok_lst.append('')\n",
    "    label_lst.append('')\n",
    "    d = {'token':tok_lst,'ner':label_lst}\n",
    "    df = pd.DataFrame(d, columns=['token','ner'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmb_conll = pd.DataFrame([])\n",
    "count=0\n",
    "for root, dirs, files in os.walk(gmb_file_path):\n",
    "#    if count > 3: limit to num of docs\n",
    "#        break\n",
    "    for fname in files:\n",
    "        if re.match(\"en.tags\",fname):\n",
    "            temp = gmb_reader(os.path.join(root,fname))\n",
    "            gmb_conll = gmb_conll.append(temp, ignore_index=True)\n",
    "            count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1436159, 2)"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmb_conll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUM-3.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "gum_file_path = '/home/ubuntu/bert-ner-datasets/GUM/CONLL-format/data-by-corpustype'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gum_reader(inpt_file):\n",
    "    f = open(inpt_file, \"r\")\n",
    "    tok_lst = ['-DOCSTART-']\n",
    "    label_lst = ['O']\n",
    "    for ix, x in enumerate(f):\n",
    "        if x == '\\n':\n",
    "            tok_lst.append('')\n",
    "            label_lst.append('')\n",
    "            continue\n",
    "        try:\n",
    "            x = x.strip()\n",
    "            split_sent = x.split('\\t')\n",
    "            tok = split_sent[0]\n",
    "            label = split_sent[1]\n",
    "            tok_lst.append(tok)\n",
    "            label_lst.append(label)\n",
    "        except:\n",
    "            print(inpt_file, ix, x)\n",
    "    f.close()\n",
    "    tok_lst.append('')\n",
    "    label_lst.append('')\n",
    "    d = {'token':tok_lst,'ner':label_lst}\n",
    "    df = pd.DataFrame(d, columns=['token','ner'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "gum_conll = pd.DataFrame([])\n",
    "count=0\n",
    "for root, dirs, files in os.walk(gum_file_path):\n",
    "    for fname in files:\n",
    "        if re.match(\".*.tsv\",fname):\n",
    "            temp = gum_reader(os.path.join(root,fname))\n",
    "            gum_conll = gum_conll.append(temp, ignore_index=True)\n",
    "            count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67077, 2)"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gum_conll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wikigold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikigold_file_path = '/home/ubuntu/bert-ner-datasets/wikigold/CONLL-format/data/wikigold.conll.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wikigold_reader(inpt_file):\n",
    "    f = open(inpt_file, \"r\")\n",
    "    tok_lst = ['-DOCSTART-', '']\n",
    "    label_lst = ['O', '']\n",
    "    for ix, x in enumerate(f):\n",
    "        if x == '\\n':\n",
    "            tok_lst.append('')\n",
    "            label_lst.append('')\n",
    "            continue\n",
    "        try:\n",
    "            x = x.strip()\n",
    "            split_sent = x.split(' ')\n",
    "            tok = split_sent[0]\n",
    "            label = split_sent[1]\n",
    "            tok_lst.append(tok)\n",
    "            label_lst.append(label)\n",
    "        except:\n",
    "            print(ix, x)\n",
    "    f.close()\n",
    "    tok_lst.append('')\n",
    "    label_lst.append('')\n",
    "    d = {'token':tok_lst,'ner':label_lst}\n",
    "    df = pd.DataFrame(d, columns=['token','ner'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikigold_conll = pd.DataFrame([])\n",
    "count=0\n",
    "temp = wikigold_reader(wikigold_file_path)\n",
    "wikigold_conll = wikigold_conll.append(temp, ignore_index=True)\n",
    "count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40996, 2)"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikigold_conll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ritter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "ritter_file_path = ['/home/ubuntu/bert-ner-datasets/Ritter/annotated/wnut16/data/train', \\\n",
    "                    '/home/ubuntu/bert-ner-datasets/Ritter/annotated/wnut16/data/test', \\\n",
    "                    '/home/ubuntu/bert-ner-datasets/Ritter/annotated/wnut16/data/dev', \\\n",
    "                    '/home/ubuntu/bert-ner-datasets/Ritter/annotated/ner.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ritter_reader(inpt_file):\n",
    "    f = open(inpt_file, \"r\")\n",
    "    tok_lst = ['-DOCSTART-', '']\n",
    "    label_lst = ['O', '']\n",
    "    for ix, x in enumerate(f):\n",
    "        if x == '\\n':\n",
    "            tok_lst.append('')\n",
    "            label_lst.append('')\n",
    "            continue\n",
    "        if x == '\\t\\n':\n",
    "            tok_lst.append('')\n",
    "            label_lst.append('')\n",
    "            continue\n",
    "        try:\n",
    "            x = x.strip()\n",
    "            split_sent = x.split('\\t')\n",
    "            tok = split_sent[0]\n",
    "            label = split_sent[1]\n",
    "            tok_lst.append(tok)\n",
    "            label_lst.append(label)\n",
    "        except:\n",
    "            print(inpt_file, ix, x)\n",
    "    f.close()\n",
    "    tok_lst.append('')\n",
    "    label_lst.append('')\n",
    "    d = {'token':tok_lst,'ner':label_lst}\n",
    "    df = pd.DataFrame(d, columns=['token','ner'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "ritter_conll = pd.DataFrame([])\n",
    "count=0\n",
    "for i in ritter_file_path:\n",
    "    temp = ritter_reader(i)\n",
    "    ritter_conll = ritter_conll.append(temp, ignore_index=True)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180763, 2)"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ritter_conll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_file_path = ['/home/ubuntu/bert-ner-datasets/BTC/CONLL-format/data/a.conll', \\\n",
    "                    '/home/ubuntu/bert-ner-datasets/BTC/CONLL-format/data/b.conll', \\\n",
    "                    '/home/ubuntu/bert-ner-datasets/BTC/CONLL-format/data/e.conll', \\\n",
    "                    '/home/ubuntu/bert-ner-datasets/BTC/CONLL-format/data/f.conll', \\\n",
    "                    '/home/ubuntu/bert-ner-datasets/BTC/CONLL-format/data/g.conll', \\\n",
    "                    '/home/ubuntu/bert-ner-datasets/BTC/CONLL-format/data/h.conll']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "def btc_reader(inpt_file):\n",
    "    f = open(inpt_file, \"r\")\n",
    "    tok_lst = ['-DOCSTART-', '']\n",
    "    label_lst = ['O', '']\n",
    "    for ix, x in enumerate(f):\n",
    "        if x == '\\n':\n",
    "            tok_lst.append('')\n",
    "            label_lst.append('')\n",
    "            continue\n",
    "        if len(x.strip().split('\\t')) == 1:\n",
    "            tok_lst.append('')\n",
    "            label_lst.append('O')\n",
    "            continue\n",
    "        try:\n",
    "            x = x.strip()\n",
    "            split_sent = x.split('\\t')\n",
    "            tok = split_sent[0]\n",
    "            label = split_sent[1]\n",
    "            tok_lst.append(tok)\n",
    "            label_lst.append(label)\n",
    "        except:\n",
    "            print(inpt_file, ix, x)\n",
    "    f.close()\n",
    "    tok_lst.append('')\n",
    "    label_lst.append('')\n",
    "    d = {'token':tok_lst,'ner':label_lst}\n",
    "    df = pd.DataFrame(d, columns=['token','ner'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_conll = pd.DataFrame([])\n",
    "count=0\n",
    "for i in btc_file_path:\n",
    "    temp = btc_reader(i)\n",
    "    btc_conll = btc_conll.append(temp, ignore_index=True)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159744, 2)"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc_conll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WNUT17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnut_file_path = ['/home/ubuntu/bert-ner-datasets/WNUT17/CONLL-format/data/train/wnut17train.conll', \\\n",
    "                  '/home/ubuntu/bert-ner-datasets/WNUT17/CONLL-format/data/test/emerging.test.annotated', \\\n",
    "                  '/home/ubuntu/bert-ner-datasets/WNUT17/CONLL-format/data/dev/emerging.dev.conll']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wnut_reader(inpt_file):\n",
    "    f = open(inpt_file, \"r\")\n",
    "    tok_lst = ['-DOCSTART-', '']\n",
    "    label_lst = ['O', '']\n",
    "    for ix, x in enumerate(f):\n",
    "        if x == '\\n':\n",
    "            tok_lst.append('')\n",
    "            label_lst.append('')\n",
    "            continue\n",
    "        try:\n",
    "            x = x.strip()\n",
    "            split_sent = x.split('\\t')\n",
    "            tok = split_sent[0]\n",
    "            label = split_sent[1]\n",
    "            tok_lst.append(tok)\n",
    "            label_lst.append(label)\n",
    "        except:\n",
    "            print(inpt_file, ix, x)\n",
    "    f.close()\n",
    "    tok_lst.append('')\n",
    "    label_lst.append('')\n",
    "    d = {'token':tok_lst,'ner':label_lst}\n",
    "    df = pd.DataFrame(d, columns=['token','ner'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnut_conll = pd.DataFrame([])\n",
    "count=0\n",
    "for i in wnut_file_path:\n",
    "    temp = wnut_reader(i)\n",
    "    wnut_conll = wnut_conll.append(temp, ignore_index=True)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107556, 2)"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnut_conll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# red3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "re3d_path = '/home/ubuntu/bert-ner-datasets/re3d/CONLL-format/data-by-source/conll'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re3d_reader(inpt_file):\n",
    "    f = open(inpt_file, \"r\")\n",
    "    tok_lst = ['-DOCSTART-', '']\n",
    "    label_lst = ['O', '']\n",
    "    for ix, x in enumerate(f):\n",
    "        if x == '\\n':\n",
    "            tok_lst.append('')\n",
    "            label_lst.append('')\n",
    "            continue\n",
    "        try:\n",
    "            x = x.strip()\n",
    "            split_sent = x.split('\\t')\n",
    "            tok = split_sent[0]\n",
    "            label = split_sent[1]\n",
    "            tok_lst.append(tok)\n",
    "            label_lst.append(label)\n",
    "        except:\n",
    "            print(inpt_file, ix, x)\n",
    "    f.close()\n",
    "    tok_lst.append('')\n",
    "    label_lst.append('')\n",
    "    d = {'token':tok_lst,'ner':label_lst}\n",
    "    df = pd.DataFrame(d, columns=['token','ner'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "re3d_conll = pd.DataFrame([])\n",
    "count=0\n",
    "for root, dirs, files in os.walk(re3d_path):\n",
    "#    if count > 3: limit to num of docs\n",
    "#        break\n",
    "    for fname in files:\n",
    "        if re.match(\".*.conll\",fname):\n",
    "            temp = re3d_reader(os.path.join(root,fname))\n",
    "            re3d_conll = re3d_conll.append(temp, ignore_index=True)\n",
    "            count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26723, 2)"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re3d_conll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEC-filings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_file_path = ['/home/ubuntu/bert-ner-datasets/SEC-filings/CONLL-format/data/train/FIN5.txt', \\\n",
    "                  '/home/ubuntu/bert-ner-datasets/SEC-filings/CONLL-format/data/test/FIN3.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sec_reader(inpt_file):\n",
    "    f = open(inpt_file, \"r\")\n",
    "    tok_lst = []\n",
    "    label_lst = []\n",
    "    for ix, x in enumerate(f):\n",
    "        if x == '\\n':\n",
    "            tok_lst.append('')\n",
    "            label_lst.append('')\n",
    "            continue\n",
    "        line = x.split()\n",
    "        tok = line[0]\n",
    "        try:\n",
    "            label = line[-1]\n",
    "        except:\n",
    "            print(line, ix)\n",
    "        tok_lst.append(tok)\n",
    "        label_lst.append(label)\n",
    "    f.close()\n",
    "    d = {'token':tok_lst,'ner':label_lst}\n",
    "    df = pd.DataFrame(d, columns=['token','ner'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_conll = pd.DataFrame([])\n",
    "count=0\n",
    "for i in sec_file_path:\n",
    "    temp = sec_reader(i)\n",
    "    sec_conll = sec_conll.append(temp, ignore_index=True)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55739, 2)"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sec_conll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_combine = pd.concat([conl2003,nltk_ieer,gmb_conll,gum_conll,wikigold_conll,ritter_conll,btc_conll,wnut_conll,re3d_conll,sec_conll])\n",
    "ner_combine=ner_combine.reset_index()\n",
    "del ner_combine['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2459768, 2)"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_combine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_combine.to_csv('ner_combine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
